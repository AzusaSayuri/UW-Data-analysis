{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 6\n",
    "\n",
    "## Problem 1: Markov Chains (40%)\n",
    "\n",
    "Download the spreadsheet ENSO_to2020.xls. (And yes, the current status of ENSO, neutral, is for water year 2020.) [Not required for the homework, but if you’re curious to learn more about ENSO and its impacts, see this website: https://www.climate.gov/enso ]\n",
    "\n",
    "Data:\t\n",
    "ENSO_to2020.xlsx\n",
    "\n",
    "## A.\n",
    "\n",
    "Using the time series of the phase of the El Niño Southern Oscillation (ENSO) (warm (El Nino) =1, neutral=2, cool (La Nina) =3) from 1900-2020, create a lag-1 Markov model of the ENSO phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "from scipy import sparse\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_excel('ENSO_to2020.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>years</th>\n",
       "      <th>phase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1900</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1901</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1902</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1903</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1904</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   years phase\n",
       "8   1900     1\n",
       "9   1901     2\n",
       "10  1902     2\n",
       "11  1903     1\n",
       "12  1904     3"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ENSO=df.iloc[8:,2:4]\n",
    "df_ENSO.columns=['years','phase']\n",
    "df_ENSO.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 2, 1, 3, 1, 1, 3, 2, 3, 3, 3, 1, 2, 1, 1, 2, 3, 3, 1, 1, 3,\n",
       "       2, 3, 1, 3, 1, 2, 2, 2, 1, 1, 3, 2, 3, 2, 2, 2, 3, 3, 1, 1, 1, 3,\n",
       "       3, 3, 2, 2, 2, 2, 3, 3, 1, 2, 2, 3, 3, 2, 1, 1, 2, 2, 2, 3, 1, 3,\n",
       "       1, 2, 3, 1, 1, 3, 3, 1, 3, 3, 3, 1, 1, 2, 1, 2, 2, 1, 3, 3, 3, 1,\n",
       "       1, 3, 2, 2, 1, 2, 2, 1, 3, 2, 1, 3, 3, 3, 2, 1, 2, 1, 3, 1, 3, 3,\n",
       "       1, 3, 3, 2, 2, 1, 1, 3, 3, 1, 2])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ENSO['phase']=df_ENSO['phase'].astype(int)\n",
    "data=np.array(df_ENSO['phase'])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0.  0.]\n",
      " [ 0. 11. 12. 17.]\n",
      " [ 0. 12. 15.  9.]\n",
      " [ 0. 16. 10. 18.]]\n"
     ]
    }
   ],
   "source": [
    "# This counts the transitions from each state to the next and marks that count\n",
    "S = sparse.csr_matrix((np.ones_like(data[:-1]), (data[:-1], data[1:])), dtype=np.float)\n",
    "\n",
    "# This converts those counts to matrix form\n",
    "tm = S.todense()\n",
    "print(tm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We had 11 counts when the series transitioned from 1 to 1, 12 counts when it transitioned from 1 to 2, etc. We want to transition these from counts to frequencies. To do this, we need to normalize the transition matrix to get probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[       nan        nan        nan        nan]\n",
      " [0.         0.275      0.3        0.425     ]\n",
      " [0.         0.33333333 0.41666667 0.25      ]\n",
      " [0.         0.36363636 0.22727273 0.40909091]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\tools\\py\\lib\\site-packages\\ipykernel_launcher.py:3: RuntimeWarning: invalid value encountered in true_divide\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "tm_norm = np.zeros_like(tm)\n",
    "for i in range(0,tm.shape[0]):\n",
    "    tm_norm[i,:] = tm[i,:] / np.sum(tm[i,:])\n",
    "    \n",
    "print(tm_norm) # This is our normalized transition matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We take the above probabilities of transitions, and turn them into discrete CDF's.\n",
    "# These will allow us to map random numbers generated from a uniform distribution into \n",
    "# transitions that follow these probability rules.\n",
    "tm_cdf = np.cumsum(tm_norm,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B.\n",
    "\n",
    "Using this Markov model and a random number generator, simulate 5,000 years of ENSO data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_years = 5000\n",
    "q = np.random.uniform(0,1,n_years); # uniformly distributed random numbers n_years long\n",
    "\n",
    "initialstate = 2; # give it an initial state, doesn't really matter which\n",
    "\n",
    "Nrand = np.zeros_like(q) # initialize an array of the proper size, with the initial state\n",
    "Nrand[0] = initialstate;\n",
    "\n",
    "# Now, just like we did when we created monte carlo simulations from empirical CDFs,\n",
    "# we use our uniform random numbers to look up the next state in the transition matrix\n",
    "for i in range(1,n_years):\n",
    "    if q[i] <= tm_cdf[int(Nrand[i-1]),1]: #probability of transitioning from state i to 1\n",
    "        Nrand[i] = 1;\n",
    "    elif q[i] <= tm_cdf[int(Nrand[i-1]),2]: #transition from state i to 2\n",
    "        Nrand[i] = 2;\n",
    "    else:\n",
    "        Nrand[i] = 3;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Nrand.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 2., 1., ..., 1., 3., 3.])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Nrand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nrand is the simulated data for next 5000 years."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C.\n",
    "\n",
    "Using this stochastically generated data, answer the following questions. According to the model, what is the probability that three warm ENSO years would occur in a row? (Try refreshing the numbers several times to increase the sample size if the condition never happens.) What is the large-sample probability that three cool ENSO years would happen in a row?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency of three warm periods in a row = 0.061%\n"
     ]
    }
   ],
   "source": [
    "# And how many times did state 3 appear 3 times?\n",
    "Test3 = [Nrand[0:-2], Nrand[1:-1], Nrand[2:]] # stack our data 3 times, shifting it to the right by 1 each time\n",
    "Test3 = np.stack(Test3, axis=1)\n",
    "\n",
    "G2 = np.where((np.max(Test3, axis=1) == 3) & (np.min(Test3, axis=1) == 3))\n",
    "# if both the maximum and the minimum are 3, then we have 3 threes in our sequence\n",
    "\n",
    "frequencyof3threes = G2[0].size / Test3.shape[0]\n",
    "\n",
    "print('Frequency of three warm periods in a row = {}%'.format(np.round(frequencyof3threes,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency of three cold periods in a row = 0.024%\n"
     ]
    }
   ],
   "source": [
    "# And how many times did state 3 appear 3 times?\n",
    "Test3 = [Nrand[0:-2], Nrand[1:-1], Nrand[2:]] # stack our data 3 times, shifting it to the right by 1 each time\n",
    "Test3 = np.stack(Test3, axis=1)\n",
    "\n",
    "G2 = np.where((np.max(Test3, axis=1) == 1) & (np.min(Test3, axis=1) == 1))\n",
    "frequencyof3threes = G2[0].size / Test3.shape[0]\n",
    "\n",
    "print('Frequency of three cold periods in a row = {}%'.format(np.round(frequencyof3threes,3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2: Application of Bayes Theorem (40%)\n",
    "\n",
    "Following the Week 6 Lab, explore how the rating curve and its associated uncertainty change whether you use least squares fitting, direct monte carlo parameter estimation, or Bayesian MCMC fitting to determine the rating curve and 95% confidence intervals for the Lyell Fork streamflow site. Create plots and discuss what you did."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3: Data Assimilation (20%)\n",
    "\n",
    "Reading:\t\n",
    "reichle-2008.pdf\n",
    "\n",
    "Read Reichle’s “Data assimilation methods in the Earth sciences”, available as reichle- 2008.pdf above and answer the following in your own words:\n",
    "\n",
    "## A.\n",
    "\n",
    "In the simple data assimilation system (section 2.1), what is the Kalman gain? What does it do, and why is it important?\n",
    "\n",
    "## B.\n",
    "\n",
    "According to Rolf Reichle, what are some of the greatest continuing challenges in data assimilation (see section 3)? List at least 3 and for each, give an example of how scientists are dealing with this challenge."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
